{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kraltendorf/HopBox/blob/main/HopBox_Infer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEhF8PEX38IV"
      },
      "source": [
        "# HopBox Inference #\n",
        "This notebook is used to run inference on a trained FCN semantic segmentation model trained to segment Hop Corns in an image.\n",
        "\n",
        "The notebook loads the model and image data paths, color corrects the images, reads the info stored in QR code, and then runs inference on the images.\n",
        "\n",
        "The notebook outputs the segmentaion results to a user specified directory.\n",
        "\n",
        "The notebook also outputs a `.csv` file with the results of the inference run. The .csv file contains the following information:\n",
        "\n",
        "- Image Name\n",
        "- QR Code informaton\n",
        "- Number of Hop Corns in the image\n",
        "- A few region properties of each Hop Corn (area, centroid, bounding box, etc.)\n",
        "- The median, standard deviation, and average RGB values of each Hop Corn\n",
        "\n",
        "\n",
        "Details on the Image data used, model training, color correction, and data analysis can be found in our [paper](https://....).\n",
        "\n",
        "\n",
        "**Note:** This is intended to be run on Google colab, but can be run on a local machine or elsewhere with little modification and the appropriate dependencies installed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3lgPkAw38IZ"
      },
      "source": [
        "# 1. Mount Google Drive\n",
        "This section mounts the Google Drive to the notebook. This is necessary to access the data and model files stored on Google Drive. \n",
        "\n",
        "Make sure to change the path to the directory where the data and model files are stored.\n",
        "\n",
        "It also lists the files in the working directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ht7oMuGEF3W",
        "outputId": "583ceea0-c12e-4a07-a735-724a0e955beb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/MyDrive/HopBox_Publication/HopBox_colab\n",
            "/content/drive/MyDrive/HopBox_Publication/HopBox_colab\n",
            "hopbox_functions.py  Hop_images     ReadMe_files\n",
            "HopBox_Infer.ipynb   hoptrial1.pth  ref_babel_avg_srgb_d50.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "#list working directory here (this is the path to the folder with this notebook, the hopbox_functions.py file, the ref_babel_avg_srgb_d50.csv file and the folder containing the images you want to analyze):\n",
        "%cd \"/content/drive/MyDrive/HopBox_Publication/HopBox_colab/\"\n",
        "!pwd\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8377MPWNzNI4"
      },
      "source": [
        "# 2. Install Dependencies\n",
        "This section installs the dependencies needed to run the notebook including:\n",
        "- Cuda version of `PyTorch` and `TorchVision`, and `TorchAudio` : The libraries used to load the model and run inference\n",
        "- `Pyzbar` : A toolbox used to read the QR code in images\n",
        "- `libzbar0` : This is only necessary if running on linux based machine eg Colab. It is used by Pyzbar to read the QR code in images\n",
        "\n",
        "Also check the assigned GPU. This is necessary to make sure the GPU is being used to run inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNzzSmCFBinr",
        "outputId": "9bf59d96-076d-4e16-dec4-4f017ae95687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.9.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp39-cp39-linux_x86_64.whl (2041.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m778.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.10.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp39-cp39-linux_x86_64.whl (23.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==0.9.0\n",
            "  Downloading torchaudio-0.9.0-cp39-cp39-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.9.0+cu111) (4.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision==0.10.0+cu111) (1.22.4)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.10.0+cu111) (8.4.0)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.1+cu116\n",
            "    Uninstalling torchvision-0.14.1+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.1+cu116\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.13.1+cu116\n",
            "    Uninstalling torchaudio-0.13.1+cu116:\n",
            "      Successfully uninstalled torchaudio-0.13.1+cu116\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.9.0+cu111 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libv4l-0 libv4lconvert0\n",
            "The following NEW packages will be installed:\n",
            "  libv4l-0 libv4lconvert0 libzbar0\n",
            "0 upgraded, 3 newly installed, 0 to remove and 22 not upgraded.\n",
            "Need to get 238 kB of archives.\n",
            "After this operation, 817 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 libv4lconvert0 amd64 1.18.0-2build1 [76.5 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 libv4l-0 amd64 1.18.0-2build1 [41.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 libzbar0 amd64 0.23-1.3 [119 kB]\n",
            "Fetched 238 kB in 1s (206 kB/s)\n",
            "Selecting previously unselected package libv4lconvert0:amd64.\n",
            "(Reading database ... 128275 files and directories currently installed.)\n",
            "Preparing to unpack .../libv4lconvert0_1.18.0-2build1_amd64.deb ...\n",
            "Unpacking libv4lconvert0:amd64 (1.18.0-2build1) ...\n",
            "Selecting previously unselected package libv4l-0:amd64.\n",
            "Preparing to unpack .../libv4l-0_1.18.0-2build1_amd64.deb ...\n",
            "Unpacking libv4l-0:amd64 (1.18.0-2build1) ...\n",
            "Selecting previously unselected package libzbar0:amd64.\n",
            "Preparing to unpack .../libzbar0_0.23-1.3_amd64.deb ...\n",
            "Unpacking libzbar0:amd64 (0.23-1.3) ...\n",
            "Setting up libv4lconvert0:amd64 (1.18.0-2build1) ...\n",
            "Setting up libv4l-0:amd64 (1.18.0-2build1) ...\n",
            "Setting up libzbar0:amd64 (0.23-1.3) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyzbar\n",
            "  Downloading pyzbar-0.1.9-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pyzbar\n",
            "Successfully installed pyzbar-0.1.9\n",
            "Thu Mar  9 21:35:38 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P0    28W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# install basic dependencies\n",
        "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!apt install libzbar0 # if linux based machine\n",
        "!pip install pyzbar\n",
        "\n",
        "#Check current/allocated cuda GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkVb-o-v38Ic"
      },
      "source": [
        "# 3. Load dependencies\n",
        "This section loads the dependencies needed to run the notebook.\n",
        "More functions are defined in the `hopbox_functions.py` file. Be sure to upload this file to the working directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSy7ABEd38Id"
      },
      "outputs": [],
      "source": [
        "# Load more dependencies\n",
        "from __future__ import print_function\n",
        "from hopbox_functions import run_inference\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "sys.path.append(os.path.join(sys.path[0])) # add current directory to path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW_7sp7o38Ie"
      },
      "source": [
        "# 4. Load the Model and Data Paths, create output directory\n",
        "This section loads the model and data paths, and creates the output directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ub8rBgPCEVKN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d519621-d0d5-4853-84d6-c9972688b1bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 image files found\n",
            "['IMG_0004.JPG', 'IMG_0003.JPG', 'IMG_0001.JPG', 'IMG_0008.JPG', 'IMG_0002.JPG', 'IMG_0001 (1).JPG', 'IMG_0011.JPG', 'IMG_0004 (1).JPG', 'IMG_0007.JPG', 'IMG_0006.JPG', 'IMG_0003 (1).JPG']\n",
            "'/content/drive/MyDrive/HopBox_Publication/HopBox_colab/analyzed_images/' already exists\n"
          ]
        }
      ],
      "source": [
        "#Put the path of the folder with your images here\n",
        "Base_folder = \"/content/drive/MyDrive/HopBox_Publication/HopBox_colab/\"\n",
        "inference_dir = Base_folder + \"Hop_images/\"\n",
        "\n",
        "filess = os.listdir(inference_dir)\n",
        "print(str(len(filess)) + \" image files found\")\n",
        "print(filess)\n",
        "\n",
        "Save_Images = 1 # 1 for saving images, and 0 for not saving images\n",
        "\n",
        "model_dir = Base_folder + \"hoptrial1.pth\"\n",
        "\n",
        "output_directory = Base_folder + \"analyzed_images/\"\n",
        "\n",
        "if Save_Images == 1:\n",
        "  mask_dir = output_directory + \"/Masks/\"\n",
        "  label_dir = output_directory + \"/Mask_labels/\"\n",
        "  corrected_dir = output_directory + \"/Corrected_imgs/\"\n",
        "\n",
        "  try:\n",
        "    os.makedirs(mask_dir)\n",
        "    os.makedirs(label_dir)\n",
        "    os.makedirs(corrected_dir)\n",
        "  except:\n",
        "    print(\"'\" + output_directory+ \"' already exists\")\n",
        "    \n",
        "directories = [inference_dir,\n",
        "               mask_dir,\n",
        "               label_dir,\n",
        "               corrected_dir,\n",
        "               model_dir,\n",
        "               output_directory\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EycH8dxF38If"
      },
      "source": [
        "# 5. Run Inference\n",
        "This section loops through the images in the data directory, reads the QR code, color corrects the image, runs inference, and saves the results to the output directory.\n",
        "\n",
        "It also saves the results described above to a `.csv` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1pgUoS4AWHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e91dfbe-ea16-48e6-dcbb-c071d0d5b0fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5184, 3456)\n",
            "Color model Fit score =  0.993565674981415\n",
            "Inference time: 0.03986525535583496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/HopBox_Publication/HopBox_colab/hopbox_functions.py:345: UserWarning: /content/drive/MyDrive/HopBox_Publication/HopBox_colab/analyzed_images//Masks/IMG_0004.JPG_mask.png is a boolean image: setting True to 255 and False to 0. To silence this warning, please convert the image using img_as_ubyte.\n",
            "  io.imsave(directories[1] + file + \"_mask.png\", mat_mask)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5184, 3456)\n",
            "Color model Fit score =  0.9934905331258633\n",
            "Inference time: 0.03682708740234375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/HopBox_Publication/HopBox_colab/hopbox_functions.py:345: UserWarning: /content/drive/MyDrive/HopBox_Publication/HopBox_colab/analyzed_images//Masks/IMG_0003.JPG_mask.png is a boolean image: setting True to 255 and False to 0. To silence this warning, please convert the image using img_as_ubyte.\n",
            "  io.imsave(directories[1] + file + \"_mask.png\", mat_mask)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5184, 3456)\n",
            "Color model Fit score =  0.9928447557437533\n",
            "Inference time: 0.04062056541442871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/HopBox_Publication/HopBox_colab/hopbox_functions.py:345: UserWarning: /content/drive/MyDrive/HopBox_Publication/HopBox_colab/analyzed_images//Masks/IMG_0001.JPG_mask.png is a boolean image: setting True to 255 and False to 0. To silence this warning, please convert the image using img_as_ubyte.\n",
            "  io.imsave(directories[1] + file + \"_mask.png\", mat_mask)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5184, 3456)\n",
            "Color model Fit score =  0.993632880491686\n",
            "Inference time: 0.03817129135131836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/HopBox_Publication/HopBox_colab/hopbox_functions.py:345: UserWarning: /content/drive/MyDrive/HopBox_Publication/HopBox_colab/analyzed_images//Masks/IMG_0008.JPG_mask.png is a boolean image: setting True to 255 and False to 0. To silence this warning, please convert the image using img_as_ubyte.\n",
            "  io.imsave(directories[1] + file + \"_mask.png\", mat_mask)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5184, 3456)\n",
            "Color model Fit score =  0.9925637463875048\n",
            "Could NOT find Bar/QR code in image!!!\n",
            "Inference time: 0.036508798599243164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/HopBox_Publication/HopBox_colab/hopbox_functions.py:345: UserWarning: /content/drive/MyDrive/HopBox_Publication/HopBox_colab/analyzed_images//Masks/IMG_0002.JPG_mask.png is a boolean image: setting True to 255 and False to 0. To silence this warning, please convert the image using img_as_ubyte.\n",
            "  io.imsave(directories[1] + file + \"_mask.png\", mat_mask)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5184, 3456)\n",
            "Color model Fit score =  0.9927746943399827\n",
            "Inference time: 0.04326510429382324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/HopBox_Publication/HopBox_colab/hopbox_functions.py:345: UserWarning: /content/drive/MyDrive/HopBox_Publication/HopBox_colab/analyzed_images//Masks/IMG_0001 (1).JPG_mask.png is a boolean image: setting True to 255 and False to 0. To silence this warning, please convert the image using img_as_ubyte.\n",
            "  io.imsave(directories[1] + file + \"_mask.png\", mat_mask)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5184, 3456)\n",
            "Color model Fit score =  0.9947615279142833\n",
            "Inference time: 0.03991127014160156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/HopBox_Publication/HopBox_colab/hopbox_functions.py:345: UserWarning: /content/drive/MyDrive/HopBox_Publication/HopBox_colab/analyzed_images//Masks/IMG_0011.JPG_mask.png is a boolean image: setting True to 255 and False to 0. To silence this warning, please convert the image using img_as_ubyte.\n",
            "  io.imsave(directories[1] + file + \"_mask.png\", mat_mask)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5184, 3456)\n",
            "Color model Fit score =  0.992622420247996\n",
            "Could NOT find Bar/QR code in image!!!\n",
            "Inference time: 0.037106990814208984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/HopBox_Publication/HopBox_colab/hopbox_functions.py:345: UserWarning: /content/drive/MyDrive/HopBox_Publication/HopBox_colab/analyzed_images//Masks/IMG_0004 (1).JPG_mask.png is a boolean image: setting True to 255 and False to 0. To silence this warning, please convert the image using img_as_ubyte.\n",
            "  io.imsave(directories[1] + file + \"_mask.png\", mat_mask)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5184, 3456)\n",
            "Color model Fit score =  0.9935835862037962\n",
            "Inference time: 0.03655219078063965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/HopBox_Publication/HopBox_colab/hopbox_functions.py:345: UserWarning: /content/drive/MyDrive/HopBox_Publication/HopBox_colab/analyzed_images//Masks/IMG_0007.JPG_mask.png is a boolean image: setting True to 255 and False to 0. To silence this warning, please convert the image using img_as_ubyte.\n",
            "  io.imsave(directories[1] + file + \"_mask.png\", mat_mask)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5184, 3456)\n",
            "Color model Fit score =  0.9927747265990172\n",
            "Inference time: 0.03802657127380371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/HopBox_Publication/HopBox_colab/hopbox_functions.py:345: UserWarning: /content/drive/MyDrive/HopBox_Publication/HopBox_colab/analyzed_images//Masks/IMG_0006.JPG_mask.png is a boolean image: setting True to 255 and False to 0. To silence this warning, please convert the image using img_as_ubyte.\n",
            "  io.imsave(directories[1] + file + \"_mask.png\", mat_mask)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5184, 3456)\n",
            "Color model Fit score =  0.9927091057881666\n",
            "Inference time: 0.03587698936462402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/HopBox_Publication/HopBox_colab/hopbox_functions.py:345: UserWarning: /content/drive/MyDrive/HopBox_Publication/HopBox_colab/analyzed_images//Masks/IMG_0003 (1).JPG_mask.png is a boolean image: setting True to 255 and False to 0. To silence this warning, please convert the image using img_as_ubyte.\n",
            "  io.imsave(directories[1] + file + \"_mask.png\", mat_mask)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to: /content/drive/MyDrive/HopBox_Publication/HopBox_colab/analyzed_images/Results.csv\n"
          ]
        }
      ],
      "source": [
        "scale = 1; # should be based image size and network input size\n",
        "\n",
        "# Reference Data \n",
        "def load_csv_chart(f):\n",
        "    '''Input CSV's shape is (24, 3), with sRGB reference values\n",
        "    '''\n",
        "    data = np.loadtxt(f,delimiter=\",\")\n",
        "    assert data.shape ==(24, 3)\n",
        "    return data\n",
        "ref = load_csv_chart(Base_folder + 'ref_babel_avg_srgb_d50.csv') # loads reference RGB color values\n",
        "\n",
        "run_inference(ref=ref, directories=directories, filess=filess, scale=scale, Save_Images=Save_Images) # run inference on images in directory"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nV0E_-PJ34mn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}